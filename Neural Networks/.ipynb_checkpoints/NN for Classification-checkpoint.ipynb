{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All Activation Functions and their Transfer Derivatives\n",
    "\n",
    "# 1. Sigmoid / Logistic Function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return x * (1-x)\n",
    "\n",
    "# 2. Rectified Linear Unit Function\n",
    "def relu(x):\n",
    "     return abs(x) * (x > 0)\n",
    "\n",
    "def drelu(x):\n",
    "     return 1. * (x > 0.)\n",
    "\n",
    "# 3. Leaky-Relu Functions\n",
    "def lrelu(x):\n",
    "    return np.where(x > 0., x, x * 0.01)\n",
    "\n",
    "def dlrelu(x):\n",
    "    dx = np.ones_like(x)\n",
    "    dx[x < 0.] = 0.01\n",
    "    return dx\n",
    "\n",
    "# 4. Hyperbolic Tan Function\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1.0 - (np.power(np.tanh(x),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feed_forward(data_in, w0,w1,w2, w3, b0,b1,b2,b3):\n",
    "    '''\n",
    "    The Feed-forward considers 5 layers including input and output layer.\n",
    "    \n",
    "    The output layer/neuron is a classification node.\n",
    "    \n",
    "    returns: state of each layer\n",
    "    '''\n",
    "    layer0 = data_in\n",
    "    layer1 = tanh(np.dot(layer0, w0)+b0)\n",
    "    layer2 = tanh(np.dot(layer1, w1)+b1)\n",
    "    layer3 = tanh(np.dot(layer2, w2)+b2)\n",
    "    layer4 = sigmoid(np.dot(layer3, w3)+b3)\n",
    "\n",
    "    return layer0, layer1, layer2, layer3, layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropogate(i, layer0, layer1, layer2, layer3, layer4, actual_y, w0,w1,w2,w3,b0,b1,b2,b3, learning_rate):\n",
    "    '''\n",
    "    This backpropogate is only slightly different from a regular classifier\n",
    "    in ways in which the output layer gradient is calculated.\n",
    "    \n",
    "    Since the output layer is not a function of any activation function,\n",
    "    the delta doesn't need to be multiplied with the transfer derivative of the\n",
    "    output layer.\n",
    "    \n",
    "    The rest is all the same.\n",
    "    \n",
    "    returns: weights and bias matrices\n",
    "    '''\n",
    "    l4_error = layer4 - actual_y\n",
    "    l4_delta = l4_error * dsigmoid(layer4)\n",
    "    dh4 = np.dot(layer3.T, l4_delta)\n",
    "    \n",
    "    l3_error = l4_delta.dot(w3.T)\n",
    "    l3_delta = l3_error * dtanh(layer3)\n",
    "    dh3 = np.dot(layer2.T, l3_delta)\n",
    "    \n",
    "    l2_error = l3_delta.dot(w2.T)\n",
    "    l2_delta = l2_error * dtanh(layer2)\n",
    "    dh2 = np.dot(layer1.T, l2_delta)\n",
    "    \n",
    "    l1_error = l2_delta.dot(w1.T)\n",
    "    l1_delta = l1_error * dtanh(layer1)\n",
    "    dh1 = np.dot(layer0.T, l1_delta)\n",
    "    \n",
    "    w3 = w3 - (learning_rate * dh4)\n",
    "    w2 = w2 - (learning_rate * dh3)\n",
    "    w1 = w1 - (learning_rate * dh2)\n",
    "    w0 = w0 - (learning_rate * dh1)\n",
    "    \n",
    "    b3 = b3 - (learning_rate * np.mean(l4_delta))\n",
    "    b2 = b2 - (learning_rate * np.mean(l3_delta))\n",
    "    b1 = b1 - (learning_rate * np.mean(l2_delta))\n",
    "    b0 = b0 - (learning_rate * np.mean(l1_delta))    \n",
    "   \n",
    "    if i%10==0 and (i!=0):\n",
    "        loss = np.mean(np.power(layer4-actual_y, 2))\n",
    "        loss_curve.append(loss)\n",
    "        iters.append(int(i))\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(\"\\n\", int(i), loss)\n",
    "\n",
    "        \n",
    "    return w0, w1,w2,w3, b0,b1,b2,b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(testx, testy):\n",
    "    correct = 0\n",
    "    layer0, layer1, layer2, layer3, layer4 = feed_forward(testx,w0, w1,w2,w3, b0,b1,b2,b3)\n",
    "    for i in range(len(testx)):\n",
    "        if np.argmax(layer4[i]) == np.argmax(testy[i]):\n",
    "            correct +=1 \n",
    "            \n",
    "    return f\"Accuracy: {correct*100/len(testy)}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on Wine Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "features = wine.data\n",
    "target = wine.target\n",
    "\n",
    "nt = []\n",
    "for i in target:\n",
    "    op = [0,0,0]\n",
    "    op[i] = 1\n",
    "    nt.append(op)\n",
    "    \n",
    "target = np.array(nt)\n",
    "\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "Y = target\n",
    "\n",
    "X = (X-X.min()) / (X.max()-X.min())\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X.values,Y, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w0 = np.random.random((13,50))\n",
    "w1 = np.random.random((50,30))\n",
    "w2 = np.random.random((30, 5))\n",
    "w3 = np.random.random((5,3))\n",
    "\n",
    "b0 = np.random.random((1,1))-1\n",
    "b1 = np.random.random((1,1))-1\n",
    "b2 = np.random.random((1,1))-1\n",
    "b3 = np.random.random((1,1))-1\n",
    "\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising variables to track loss vs iterations so we can plot the changes\n",
    "loss_curve = []\n",
    "iters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf247e02dff41bbb41744e486356cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 100 0.15400280727369378\n",
      "\n",
      " 200 0.1351893228939147\n",
      "\n",
      " 300 0.06288016796649286\n",
      "\n",
      " 400 0.035321969876057104\n",
      "\n",
      " 500 0.015974160214950964\n",
      "\n",
      " 600 0.00984092978244509\n",
      "\n",
      " 700 0.0070802346673510255\n",
      "\n",
      " 800 0.005402074660748096\n",
      "\n",
      " 900 0.004278206062177097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(epochs)):\n",
    "    layer0, layer1, layer2, layer3, layer4 = feed_forward(xtrain, w0,w1,w2, w3, b0,b1,b2,b3)\n",
    "    w0,w1,w2, w3, b0,b1,b2,b3 = backpropogate(i,layer0, layer1, layer2, layer3, layer4, ytrain, w0,w1,w2, w3, b0,b1,b2,b3, 0.005 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c54df99908>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyKVeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c54df250f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iters, loss_curve,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 100.0%'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 93.7062937062937%'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
